# Prometheus Alert Rules for X-Form Backend Microservices
# Comprehensive alerts for all services and infrastructure

groups:
  - name: xform.api-gateway.rules
    rules:
      # API Gateway Alerts
      - alert: APIGatewayDown
        expr: up{job="api-gateway"} == 0
        for: 1m
        labels:
          severity: critical
          service: api-gateway
          category: availability
        annotations:
          summary: "API Gateway is down"
          description: "API Gateway instance {{ $labels.instance }} is not responding"
          runbook_url: "https://runbooks.xform.com/api-gateway-down"

      - alert: APIGatewayHighErrorRate
        expr: rate(xform_http_requests_total{job="api-gateway",status_code=~"5.."}[5m]) / rate(xform_http_requests_total{job="api-gateway"}[5m]) > 0.1
        for: 5m
        labels:
          severity: critical
          service: api-gateway
          category: errors
        annotations:
          summary: "High error rate in API Gateway"
          description: "API Gateway error rate is {{ $value | humanizePercentage }} for {{ $labels.instance }}"

      - alert: APIGatewayHighLatency
        expr: histogram_quantile(0.95, rate(xform_http_request_duration_seconds_bucket{job="api-gateway"}[5m])) > 2
        for: 10m
        labels:
          severity: warning
          service: api-gateway
          category: performance
        annotations:
          summary: "High latency in API Gateway"
          description: "95th percentile latency is {{ $value }}s for {{ $labels.instance }}"

      - alert: APIGatewayProxyErrors
        expr: rate(xform_service_errors_total{job="api-gateway",error_type="proxy_error"}[5m]) > 0.1
        for: 5m
        labels:
          severity: warning
          service: api-gateway
          category: proxy
        annotations:
          summary: "High proxy error rate"
          description: "Proxy error rate is {{ $value }} errors/s for {{ $labels.instance }}"

  - name: xform.auth-service.rules
    rules:
      # Auth Service Alerts
      - alert: AuthServiceDown
        expr: up{job="auth-service"} == 0
        for: 1m
        labels:
          severity: critical
          service: auth-service
          category: availability
        annotations:
          summary: "Auth Service is down"
          description: "Auth Service instance {{ $labels.instance }} is not responding"

      - alert: AuthenticationFailureSpike
        expr: rate(xform_business_events_total{job="auth-service",event_type="authentication",status="error"}[5m]) > 10
        for: 3m
        labels:
          severity: warning
          service: auth-service
          category: security
        annotations:
          summary: "High authentication failure rate"
          description: "Authentication failure rate is {{ $value }} failures/s"

      - alert: JWTTokenValidationErrors
        expr: rate(xform_service_errors_total{job="auth-service",error_type="jwt_validation"}[5m]) > 5
        for: 5m
        labels:
          severity: warning
          service: auth-service
          category: security
        annotations:
          summary: "High JWT validation error rate"
          description: "JWT validation error rate is {{ $value }} errors/s"

  - name: xform.form-service.rules
    rules:
      # Form Service Alerts
      - alert: FormServiceDown
        expr: up{job="form-service"} == 0
        for: 1m
        labels:
          severity: critical
          service: form-service
          category: availability
        annotations:
          summary: "Form Service is down"
          description: "Form Service instance {{ $labels.instance }} is not responding"

      - alert: FormCreationErrors
        expr: rate(xform_business_events_total{job="form-service",event_type="form_creation",status="error"}[5m]) > 0.1
        for: 5m
        labels:
          severity: warning
          service: form-service
          category: business
        annotations:
          summary: "High form creation error rate"
          description: "Form creation error rate is {{ $value }} errors/s"

      - alert: DatabaseConnectionIssues
        expr: xform_db_connections_active{job="form-service"} == 0
        for: 2m
        labels:
          severity: critical
          service: form-service
          category: database
        annotations:
          summary: "No active database connections"
          description: "Form Service has no active database connections"

  - name: xform.response-service.rules
    rules:
      # Response Service Alerts
      - alert: ResponseServiceDown
        expr: up{job="response-service"} == 0
        for: 1m
        labels:
          severity: critical
          service: response-service
          category: availability
        annotations:
          summary: "Response Service is down"
          description: "Response Service instance {{ $labels.instance }} is not responding"

      - alert: ResponseSubmissionErrors
        expr: rate(xform_business_events_total{job="response-service",event_type="response_submission",status="error"}[5m]) > 0.1
        for: 5m
        labels:
          severity: warning
          service: response-service
          category: business
        annotations:
          summary: "High response submission error rate"
          description: "Response submission error rate is {{ $value }} errors/s"

  - name: xform.collaboration-service.rules
    rules:
      # Collaboration Service Alerts
      - alert: CollaborationServiceDown
        expr: up{job="collaboration-service"} == 0
        for: 1m
        labels:
          severity: critical
          service: collaboration-service
          category: availability
        annotations:
          summary: "Collaboration Service is down"
          description: "Collaboration Service instance {{ $labels.instance }} is not responding"

      - alert: WebSocketConnectionErrors
        expr: rate(xform_service_errors_total{job="collaboration-service",error_type="websocket"}[5m]) > 1
        for: 5m
        labels:
          severity: warning
          service: collaboration-service
          category: websocket
        annotations:
          summary: "High WebSocket connection error rate"
          description: "WebSocket error rate is {{ $value }} errors/s"

  - name: xform.realtime-service.rules
    rules:
      # Realtime Service Alerts
      - alert: RealtimeServiceDown
        expr: up{job="realtime-service"} == 0
        for: 1m
        labels:
          severity: critical
          service: realtime-service
          category: availability
        annotations:
          summary: "Realtime Service is down"
          description: "Realtime Service instance {{ $labels.instance }} is not responding"

      - alert: EventBroadcastErrors
        expr: rate(xform_business_events_total{job="realtime-service",event_type="event_broadcast",status="error"}[5m]) > 0.1
        for: 5m
        labels:
          severity: warning
          service: realtime-service
          category: events
        annotations:
          summary: "High event broadcast error rate"
          description: "Event broadcast error rate is {{ $value }} errors/s"

  - name: xform.analytics-service.rules
    rules:
      # Analytics Service Alerts
      - alert: AnalyticsServiceDown
        expr: up{job="analytics-service"} == 0
        for: 1m
        labels:
          severity: critical
          service: analytics-service
          category: availability
        annotations:
          summary: "Analytics Service is down"
          description: "Analytics Service instance {{ $labels.instance }} is not responding"

      - alert: DataProcessingLag
        expr: xform_business_metrics{job="analytics-service",metric_name="processing_lag"} > 300
        for: 10m
        labels:
          severity: warning
          service: analytics-service
          category: performance
        annotations:
          summary: "High data processing lag"
          description: "Data processing lag is {{ $value }} seconds"

  - name: xform.infrastructure.rules
    rules:
      # System Resource Alerts
      - alert: HighMemoryUsage
        expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) > 0.9
        for: 10m
        labels:
          severity: warning
          category: system
        annotations:
          summary: "High memory usage"
          description: "Memory usage is {{ $value | humanizePercentage }} on {{ $labels.instance }}"

      - alert: HighCPUUsage
        expr: 100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 90
        for: 15m
        labels:
          severity: warning
          category: system
        annotations:
          summary: "High CPU usage"
          description: "CPU usage is {{ $value }}% on {{ $labels.instance }}"

      - alert: DiskSpaceLow
        expr: (node_filesystem_avail_bytes / node_filesystem_size_bytes) < 0.1
        for: 5m
        labels:
          severity: critical
          category: system
        annotations:
          summary: "Low disk space"
          description: "Disk space is {{ $value | humanizePercentage }} available on {{ $labels.instance }}"

      # Container Alerts
      - alert: ContainerHighMemory
        expr: (container_memory_usage_bytes / container_spec_memory_limit_bytes) > 0.9
        for: 10m
        labels:
          severity: warning
          category: container
        annotations:
          summary: "Container high memory usage"
          description: "Container {{ $labels.name }} memory usage is {{ $value | humanizePercentage }}"

      - alert: ContainerRestarting
        expr: rate(container_start_time_seconds[10m]) > 0
        for: 0m
        labels:
          severity: warning
          category: container
        annotations:
          summary: "Container restarting"
          description: "Container {{ $labels.name }} has restarted"

  - name: xform.observability.rules
    rules:
      # Observability Infrastructure Alerts
      - alert: PrometheusTargetDown
        expr: up == 0
        for: 2m
        labels:
          severity: warning
          category: monitoring
        annotations:
          summary: "Prometheus target down"
          description: "{{ $labels.job }} target {{ $labels.instance }} is down"

      - alert: OpenTelemetryCollectorDown
        expr: up{job="otel-collector"} == 0
        for: 1m
        labels:
          severity: critical
          category: monitoring
        annotations:
          summary: "OpenTelemetry Collector is down"
          description: "OTEL Collector is not collecting traces and metrics"

      - alert: TracingExportFailures
        expr: rate(otelcol_exporter_send_failed_spans[5m]) > 10
        for: 5m
        labels:
          severity: warning
          category: tracing
        annotations:
          summary: "High tracing export failure rate"
          description: "Tracing export failure rate is {{ $value }} spans/s"

      - alert: GrafanaDown
        expr: up{job="grafana"} == 0
        for: 2m
        labels:
          severity: warning
          category: monitoring
        annotations:
          summary: "Grafana is down"
          description: "Grafana dashboard is not accessible"
