# Prometheus Alert Rules for Event Bus Service
# These rules define alerts for various system and application metrics

groups:
  - name: event-bus-service.rules
    rules:
      # HTTP Request Alerts
      - alert: HighHTTPErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) / rate(http_requests_total[5m]) > 0.1
        for: 5m
        labels:
          severity: critical
          service: event-bus-service
          category: http
        annotations:
          summary: "High HTTP error rate detected"
          description: "HTTP error rate is {{ $value | humanizePercentage }} for service {{ $labels.instance }}"
          runbook_url: "https://runbooks.example.com/http-errors"

      - alert: HighHTTPRequestLatency
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 1
        for: 10m
        labels:
          severity: warning
          service: event-bus-service
          category: http
        annotations:
          summary: "High HTTP request latency"
          description: "95th percentile latency is {{ $value }}s for {{ $labels.instance }}"

      - alert: HTTPRequestVolumeHigh
        expr: rate(http_requests_total[5m]) > 100
        for: 15m
        labels:
          severity: warning
          service: event-bus-service
          category: http
        annotations:
          summary: "High HTTP request volume"
          description: "Request rate is {{ $value }} req/s for {{ $labels.instance }}"

      # Event Processing Alerts
      - alert: EventProcessingErrorRate
        expr: rate(event_processing_errors_total[5m]) / rate(events_consumed_total[5m]) > 0.05
        for: 5m
        labels:
          severity: critical
          service: event-bus-service
          category: events
        annotations:
          summary: "High event processing error rate"
          description: "Event error rate is {{ $value | humanizePercentage }} for {{ $labels.instance }}"

      - alert: EventProcessingLag
        expr: increase(events_produced_total[5m]) - increase(events_consumed_total[5m]) > 1000
        for: 10m
        labels:
          severity: warning
          service: event-bus-service
          category: events
        annotations:
          summary: "Event processing lag detected"
          description: "Event lag is {{ $value }} events for {{ $labels.instance }}"

      - alert: NoEventsProcessed
        expr: rate(events_consumed_total[10m]) == 0
        for: 15m
        labels:
          severity: warning
          service: event-bus-service
          category: events
        annotations:
          summary: "No events being processed"
          description: "No events consumed in the last 10 minutes for {{ $labels.instance }}"

      # Kafka Alerts
      - alert: KafkaConnectionDown
        expr: kafka_connection_status == 0
        for: 2m
        labels:
          severity: critical
          service: event-bus-service
          category: kafka
        annotations:
          summary: "Kafka connection down"
          description: "Kafka connection is down for {{ $labels.instance }}"

      - alert: KafkaOperationErrors
        expr: rate(kafka_operations_total{status="error"}[5m]) > 0.1
        for: 5m
        labels:
          severity: warning
          service: event-bus-service
          category: kafka
        annotations:
          summary: "High Kafka operation error rate"
          description: "Kafka error rate is {{ $value }} errors/s for {{ $labels.instance }}"

      # CDC Alerts
      - alert: CDCConnectorDown
        expr: cdc_connector_status == 0
        for: 5m
        labels:
          severity: critical
          service: event-bus-service
          category: cdc
        annotations:
          summary: "CDC connector is down"
          description: "CDC connector {{ $labels.connector }} is down for {{ $labels.instance }}"

      - alert: CDCProcessingLag
        expr: cdc_lag_seconds > 300
        for: 10m
        labels:
          severity: warning
          service: event-bus-service
          category: cdc
        annotations:
          summary: "High CDC processing lag"
          description: "CDC lag is {{ $value }}s for connector {{ $labels.connector }}"

      # System Resource Alerts
      - alert: HighMemoryUsage
        expr: go_memstats_heap_inuse_bytes / go_memstats_heap_sys_bytes > 0.9
        for: 10m
        labels:
          severity: warning
          service: event-bus-service
          category: system
        annotations:
          summary: "High memory usage"
          description: "Memory usage is {{ $value | humanizePercentage }} for {{ $labels.instance }}"

      - alert: HighGoroutineCount
        expr: go_goroutines > 1000
        for: 15m
        labels:
          severity: warning
          service: event-bus-service
          category: system
        annotations:
          summary: "High goroutine count"
          description: "Goroutine count is {{ $value }} for {{ $labels.instance }}"

      - alert: ServiceDown
        expr: up{job="event-bus-service"} == 0
        for: 1m
        labels:
          severity: critical
          service: event-bus-service
          category: availability
        annotations:
          summary: "Event Bus Service is down"
          description: "Service {{ $labels.instance }} is not responding"

      # Business Logic Alerts
      - alert: LowBusinessMetricActivity
        expr: rate(business_metric_total[10m]) < 0.1
        for: 20m
        labels:
          severity: warning
          service: event-bus-service
          category: business
        annotations:
          summary: "Low business activity detected"
          description: "Business metric rate is {{ $value }} for {{ $labels.instance }}"

  - name: infrastructure.rules
    rules:
      # Database Alerts
      - alert: DatabaseConnectionFailure
        expr: database_connection_status == 0
        for: 2m
        labels:
          severity: critical
          service: event-bus-service
          category: database
        annotations:
          summary: "Database connection failure"
          description: "Cannot connect to database for {{ $labels.instance }}"

      # External Service Alerts
      - alert: ExternalServiceTimeout
        expr: rate(external_service_requests_total{status="timeout"}[5m]) > 0.1
        for: 5m
        labels:
          severity: warning
          service: event-bus-service
          category: external
        annotations:
          summary: "High external service timeout rate"
          description: "External service timeout rate is {{ $value }} for {{ $labels.service }}"

      # Circuit Breaker Alerts
      - alert: CircuitBreakerOpen
        expr: circuit_breaker_status == 1
        for: 1m
        labels:
          severity: warning
          service: event-bus-service
          category: circuit-breaker
        annotations:
          summary: "Circuit breaker is open"
          description: "Circuit breaker for {{ $labels.service }} is open"

  - name: tracing.rules
    rules:
      # Tracing Alerts
      - alert: TracingExportFailures
        expr: rate(otelcol_exporter_send_failed_spans[5m]) > 10
        for: 5m
        labels:
          severity: warning
          service: otel-collector
          category: tracing
        annotations:
          summary: "High tracing export failure rate"
          description: "Tracing export failure rate is {{ $value }} spans/s"

      - alert: HighTraceLatency
        expr: histogram_quantile(0.95, rate(trace_duration_seconds_bucket[5m])) > 5
        for: 10m
        labels:
          severity: warning
          service: event-bus-service
          category: tracing
        annotations:
          summary: "High trace latency detected"
          description: "95th percentile trace latency is {{ $value }}s"
